# OpenAI API Configuration
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_api_key_here

# ChromaDB Configuration
# Directory where ChromaDB will persist vector data
CHROMA_PERSIST_DIRECTORY=./data/chroma_db

# Model Configuration
# Embedding model for converting text to vectors (runs locally)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# OpenAI GPT model for generating answers
# Options: gpt-4-turbo-preview, gpt-4, gpt-3.5-turbo
OPENAI_MODEL=gpt-4-turbo-preview

# Chunking Configuration
# Size of text chunks in characters
CHUNK_SIZE=1000

# Overlap between chunks to maintain context
CHUNK_OVERLAP=200

# Upload Configuration
# Maximum file size for uploads in megabytes
MAX_UPLOAD_SIZE_MB=10

# ============================================================================
# Tavily AI Search API Configuration
# ============================================================================

# Tavily API Key for web research features
# Get your free key from: https://tavily.com
TAVILY_API_KEY=your_tavily_api_key_here

# Research Configuration
# Number of diverse search queries to generate per research topic (3-5 recommended)
RESEARCH_QUERIES_COUNT=4

# Number of results to retrieve per search query (3-10 recommended)
RESULTS_PER_QUERY=5

# Search depth: "basic" (faster, cheaper) or "advanced" (more thorough)
SEARCH_DEPTH=basic

# Maximum total web results to process per research session
MAX_RESEARCH_RESULTS=20

# Web content chunking (web content may need different sizes than documents)
WEB_CHUNK_SIZE=800
WEB_CHUNK_OVERLAP=150

# ============================================================================
# Vision Processing Configuration
# ============================================================================

# Enable image understanding (extracts and analyzes images from documents)
ENABLE_IMAGE_PROCESSING=true

# Vision model for image analysis
# Options: gpt-4-vision-preview, gpt-4o (gpt-4o is faster and cheaper)
VISION_MODEL=gpt-4o

# Maximum number of images to process per document (to control costs)
MAX_IMAGES_PER_DOCUMENT=20

# Minimum image size to process (skip tiny icons/decorations)
# Width x Height in pixels
MIN_IMAGE_SIZE=100x100

# Image detail level for vision API: "low" (cheaper, faster) or "high" (more detailed)
IMAGE_DETAIL_LEVEL=low

# ============================================================================
# PowerPoint Processing Configuration
# ============================================================================

# Enable PowerPoint (.pptx) file processing
ENABLE_PPTX_PROCESSING=true

# Maximum number of slides to process per PowerPoint document
MAX_SLIDES_PER_DOCUMENT=100

# Extract and analyze images from slides (requires image processing enabled)
EXTRACT_SLIDE_IMAGES=true

# Include speaker notes in the searchable content
INCLUDE_SPEAKER_NOTES=true

# Chunk size for PowerPoint slide content (larger than regular text for slide context)
PPTX_CHUNK_SIZE=1000

# Preserve slide structure (keeps title, body, and notes together)
PRESERVE_SLIDE_STRUCTURE=true

# ============================================================================
# Excel Processing Configuration
# ============================================================================

# Enable Excel (.xlsx, .xls) file processing
ENABLE_EXCEL_PROCESSING=true

# Maximum number of sheets to process per Excel file
MAX_SHEETS_PER_FILE=10

# Maximum rows to process per sheet (to control processing time and cost)
MAX_ROWS_PER_SHEET=1000

# Include empty cells in output (false = skip empty cells for cleaner results)
INCLUDE_EMPTY_CELLS=false

# Preserve Excel formulas (show formulas in addition to calculated values)
PRESERVE_FORMULAS=false

# Chunk size for Excel content (larger to keep related data together)
EXCEL_CHUNK_SIZE=1500

# How to chunk Excel data: "by_sheet" (each sheet is one chunk) or "by_rows" (split large sheets)
EXCEL_CHUNKING_STRATEGY=by_sheet
